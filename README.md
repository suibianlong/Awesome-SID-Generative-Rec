# Awesome Modular Semantic-based Generative Recommendation

> A curated list of resources based on the **Five-Stage Modular Analysis Framework**:
> **Representation** $\rightarrow$ **Tokenization** $\rightarrow$ **Generative Backbone** $\rightarrow$ **Training Paradigm** $\rightarrow$ **Inference**.

## ğŸ“– Taxonomy Overview

This repository organizes Generative Recommendation (GenRec) research not by listing papers chronologically, but by dissecting them into the **modular pipeline**. This perspective reveals how different methods innovate at specific stages of the generation process.

---

## 1. Representation Layer
*Capture the input semantics before discrete quantization.*

| Strategy | Description | Representative Papers |
| :--- | :--- | :--- |
| **Semantic Embedding** | Utilizing PLMs (BERT/ViT) to extract textual or visual features. | **TIGER** (NeurIPS'23) |
| **Collaborative / Graph** | Fusing interaction signals (CF) into the semantic space. | **EAGER** (arXiv'23), **LC-Rec** (WWW'24) |
| **Multimodal Unified** | Jointly modeling text, image, and ID features. | **MQL4GRec** |

| Strategy Family | Sub-Category | Paper's Tokenization & Details |
| :--- | :--- | :--- |
| **Semantic Embedding** | | **TIGER** <br>  <br> *ä½¿ç”¨è¯­ä¹‰ä¿¡æ¯è¡¨ç¤ºitem* |
| **Semantic Embedding** | **Multi-source Semantic** | **GREAM** <br>  <br> *ä½¿ç”¨å¤šæºä¿¡å·ï¼ˆåŒ…æ‹¬ç‰©å“çš„æ ‡é¢˜ã€å®˜æ–¹æè¿°å’Œé«˜è´¨é‡ç”¨æˆ·è¯„è®ºï¼‰ï¼Œå¹¶ä½¿ç”¨LLMå¯¹è¿™äº›ä¿¡æ¯è¿›è¡Œé‡å†™ï¼Œå®ç°å…¨é¢ã€ç‰¹å¾ä¸°å¯Œçš„ç‰©å“æè¿°ï¼Œæœ€åå°†é‡å†™åçš„ä¿¡æ¯ä½¿ç”¨LLMç¼–ç å½¢æˆåµŒå…¥å‘é‡* |
| **Collaborative / Graph** | **Semantic+ååŒ** | **LETTER** <br>  <br> *ä¸ä»…ä½¿ç”¨ç‰©å“çš„è¯­ä¹‰ä¿¡æ¯ï¼ˆå¦‚æ ‡é¢˜ã€æè¿°ï¼‰ï¼Œå¹¶åœ¨åé¢é€šè¿‡å¯¹æ¯”å­¦ä¹ å°†ååŒè¿‡æ»¤ä¿¡å·ä¸è¯­ä¹‰ä¿¡å·å¯¹é½*  |
| **Collaborative / Graph** | **äº¤äº’ä¿¡æ¯+è¯­ä¹‰ä¿¡æ¯** | **P5** <br>  <br> *æ„å»ºä¸€ä¸ªè¦†ç›–äº”å¤§æ¨èä»»åŠ¡æ—ï¼ˆè¯„åˆ†é¢„æµ‹ã€åºåˆ—æ¨èã€è§£é‡Šç”Ÿæˆã€è¯„è®ºæ‘˜è¦ã€ç›´æ¥æ¨èï¼‰çš„ä¸ªæ€§åŒ–æç¤ºæ¨¡æ¿é›†åˆï¼Œå°†æ‰€æœ‰çš„æ¨èæ•°æ®ï¼ˆç”¨æˆ·ã€ç‰©å“ã€äº¤äº’ã€ä¸Šä¸‹æ–‡ï¼‰ç»Ÿä¸€æ ¼å¼åŒ–ä¸ºè‡ªç„¶è¯­è¨€åºåˆ—ã€‚*  |
| **Collaborative / Graph** | **LLMs** | **LC-Rec** <br>  <br> *ä½¿ç”¨LLMç”Ÿæˆæœ€åˆçš„ç‰©å“è¡¨ç¤ºï¼Œä»–æ‰€è½¬æ¢çš„ä¿¡æ¯ä¸ºäº¤äº’ä¿¡æ¯ï¼Œå¹¶éå•çº¯çš„æ–‡æœ¬ä¿¡æ¯*  |
| **Collaborative / Graph** | **Dual Codes** | **EAGER** (arXiv'23) <br> [EAGERåŒæµç»“æ„å›¾] <br> *åŒæ—¶æ¥å—è¡Œä¸ºåŠè¯­ä¹‰ä¿¡æ¯ï¼Œä¸¤éƒ¨åˆ†åˆ†åˆ«é€šè¿‡ä¸åŒçš„é¢„è®­ç»ƒæ¥ç”Ÿæˆembedding representationï¼Œå¹¶åˆ†åˆ«å°†å…¶ä¼ ç»™åé¢çš„tokenizerå¤„ç†ã€‚*|
| **Collaborative / Graph** | **Collaborative** | **GPT4Rec**  <br>  <br> *å°†ç”¨æˆ·å…´è¶£è¡¨ç¤ºä¸ºä¸€ä¸ªç”±æ¨¡å‹åŠ¨æ€ç”Ÿæˆçš„ã€å¯è¯»çš„ã€å…·æœ‰æœç´¢æ„å›¾çš„æŸ¥è¯¢åºåˆ—ã€‚* |
| **Collaborative / Graph** | **Graph** | **SGL**  <br>  <br> *1.ä½¿ç”¨ç”¨æˆ·-ç‰©å“äº¤äº’å›¾çš„é«˜é˜¶é‚»å±…ä¿¡æ¯æ¥è¡¨ç¤ºç”¨æˆ·å’Œç‰©å“ï¼Œè€Œéä»…ä½¿ç”¨IDæˆ–ç›´æ¥äº¤äº’å†å²ã€‚2.é€šè¿‡å›¾å·ç§¯ç½‘ç»œ è¿›è¡Œå¤šå±‚é‚»å±…èšåˆï¼Œæ•æ‰å¤šè·³ååŒä¿¡å·ã€‚3.å¼•å…¥è‡ªç›‘ç£ä»»åŠ¡å¢å¼ºè¡¨ç¤ºå­¦ä¹ ï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ å¼ºåŒ–èŠ‚ç‚¹è¡¨ç¤ºã€‚* |
| **Multimodal Unified** | | **MQL4GRec** <br>  <br> *ä½¿ç”¨å¤šæ¨¡æ€ä¿¡æ¯å…±åŒé¢„æµ‹ï¼Œæ¯ç§å•ç‹¬ä½¿ç”¨å¯¹åº”çš„é¢„è®­ç»ƒæ¨¡å‹è½¬æ¢ä¸ºåµŒå…¥å‘é‡* |

---

## 2. Tokenization Layer: Discretization for Generation
*å°†è¿ç»­è¡¨å¾ç¦»æ•£åŒ–ä¸ºå¯ç”Ÿæˆ Token (Codebooks)ã€‚*

| Tokenizer Family | Sub-Category | Paper's Tokenization Focus & Details |
| :--- | :--- | :--- |
| **Residual Quantization (RQ)** | **RQ-VAE** | **TIGER** (NeurIPS'23) <br> <img src="./assets/Tokenization-TIGER.png" width="600" /> <br> *åˆ©ç”¨å¤šå±‚æ®‹å·®é‡åŒ–å™¨å°† Item Embedding ç¼–ç ä¸ºå›ºå®šé•¿åº¦çš„ Token åºåˆ—ï¼Œé¦–æ¬¡å®ç° ID åˆ° Token çš„è½¬æ¢ã€‚* |
| | **RQ-VAE** | **LETTER** <br>  <br> *åœ¨è®­ç»ƒTokenizerçš„é˜¶æ®µï¼Œé€šè¿‡ä¸€ä¸ªå¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°ï¼Œå¼ºåˆ¶è¦æ±‚ç”±åˆ†è¯å™¨ç”Ÿæˆçš„ç‰©å“é‡åŒ–åµŒå…¥ä¸ä¸€ä¸ªè®­ç»ƒå¥½çš„ååŒè¿‡æ»¤æ¨¡å‹çš„åµŒå…¥å¯¹é½ï¼›å¹¶å¼•å…¥å¤šæ ·æ€§æ­£åˆ™åŒ–ç¼“è§£ä»£ç åˆ†é…åå·®å¼•å…¥* |
| | **RQ-VAE** | **LC-Rec** <br>  <br> *ä½¿ç”¨RQ-VAEå®ç°ä»embeddingåˆ°item IDçš„è½¬æ¢ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è§£å†³è¯­ä¹‰æ˜ å°„å†²çªçš„æ–¹å¼ï¼Œå¼•å…¥uniform distribution constraintï¼Œå°†è¿™ä¸ªå‡åŒ€è¯­ä¹‰æ˜ å°„çš„ä»»åŠ¡è½¬æ¢ä¸ºoptimal transmission problemï¼Œå¹¶é€šè¿‡Sinkhorn-Knopp algorithmè§£å†³ã€‚* |
| | **RQ-VAE** | **MQL4GRec** <br>  <br> *æ¯ä¸ªæ¨¡æ€ï¼ˆæ–‡æœ¬ã€å›¾åƒï¼‰è®­ç»ƒä¸€ä¸ªç‹¬ç«‹çš„RQ-VAEç¿»è¯‘å™¨ï¼Œå®ç°ä¸åŒæ¨¡æ€çš„ä¿¡å·åœ¨è¾“å‡ºç©ºé—´çš„è¯­ä¹‰ä¸Šå¯¹é½* |
| | **Multi-Head VQ-VAE** | **LLaDA-Rec** <br>  <br> *æå‡º Multi-Head VQ-VAE æ¥ç”Ÿæˆå¹¶è¡Œçš„è¯­ä¹‰IDã€‚å…·ä½“åšæ³•æ˜¯ï¼šå°†ç‰©å“çš„è¯­ä¹‰å‘é‡åˆ†å‰²æˆMä¸ªå­å‘é‡ï¼Œæ¯ä¸ªå­å‘é‡åˆ†åˆ«ä½¿ç”¨ä¸€ä¸ªç‹¬ç«‹çš„ç æœ¬è¿›è¡Œé‡åŒ–* |
| | **R-KMeans** | OneRec  |
| **Product Quantization (PQ)** | **OPQ** | **RPG** (KDD'25) <br> [RPGå¹¶è¡Œç”Ÿæˆ/OPQç¤ºæ„å›¾] <br> *è´¡çŒ®: é‡‡ç”¨äº†ç±»ä¼¼ OPQ çš„ç»“æ„æ¥æ„å»º Long Semantic IDï¼Œä»¥æ”¯æŒéè‡ªå›å½’çš„å¹¶è¡Œç”Ÿæˆï¼Œè§£å†³äº†çŸ­ ID è¯­ä¹‰å®¹é‡ä¸è¶³çš„é—®é¢˜ã€‚* |
| **Clustering-based** | **Hierarchical K-Means** | **GenRet** (NeurIPS'22) <br> [GenRetæ ‘ç»“æ„IDç”Ÿæˆå›¾] <br> *è´¡çŒ®: å°† Item ID ç¼–ç æˆæ ‘è·¯å¾„åºåˆ—ï¼Œåˆ©ç”¨å±‚æ¬¡ K-Means èšç±»æ„å»ºæ ‘ç»“æ„ï¼Œå°†ç”Ÿæˆé—®é¢˜è½¬åŒ–ä¸ºè·¯å¾„ç”Ÿæˆã€‚* |
| | **Hierarchical K-Means** | **SEER** (RecSys'23) <br> [SEER IDè§£é‡Šæ€§ç»“æ„å›¾] <br> *è´¡çŒ®: é‡‡ç”¨å±‚æ¬¡åŒ–çš„ç¦»æ•£ ID ç»“æ„ï¼Œåˆ©ç”¨èšç±»ç»“æœæ¥æä¾›æ¨èçš„å¯è§£é‡Šæ€§ï¼Œå¹¶æŒ‡å¯¼ç”Ÿæˆè¿‡ç¨‹ã€‚* |
| | **Hierarchical K-Means** | **ColaRec** <br> <br> *è´¡çŒ®: ä½¿ç”¨å±‚æ¬¡åŒ–K-meanså¯¹CFä¿¡å·æ„å»ºå¯¹åº”çš„GID* |
| **Hybrid / Textual** | **Raw Text Tokens** | **GPT4Rec** (SIGIR eCom'23) <br> [GPT4Rec Query/Textç”Ÿæˆæµç¨‹å›¾] <br> *è´¡çŒ®: å°†ç”¨æˆ·å†å²è½¬åŒ–ä¸ºæ–‡æœ¬ Queryï¼Œç„¶åç”Ÿæˆ Item Title ç­‰æè¿°æ€§æ–‡æœ¬ï¼Œå®Œå…¨ç»•è¿‡äº† Item ID è¯­ä¹‰é‡åŒ–æ­¥éª¤ã€‚* |
| **Learnable / E2E** | **Joint Optimization** | **LC-Rec** (WWW'24) <br> [LC-Recè”åˆä¼˜åŒ–æ¡†å›¾] <br> *è´¡çŒ®: æå‡ºäº†å¯å­¦ä¹ çš„ä»£ç æœ¬ï¼Œè®©é‡åŒ–å™¨åœ¨æ¨èä»»åŠ¡ä¸­åŒæ­¥ä¼˜åŒ–ï¼Œä»¥é€‚é…ç”Ÿæˆå¼éª¨å¹²ã€‚* |
| | **Joint Optimization** | **ETEGRec** (CIKM'24) <br> [ETEGRecç«¯åˆ°ç«¯æ¶æ„å›¾] <br> *è´¡çŒ®: ä¾§é‡äºå®ç° Tokenizer ä¸ç”Ÿæˆæ¨¡å—çš„ç«¯åˆ°ç«¯å¯è®­ç»ƒæ€§ï¼Œå‡å°‘é‡åŒ–è¯¯å·®å¯¹æ¨èæ€§èƒ½çš„å½±å“ã€‚* |
| **Sperate Words** | **BERT Tokenizer** | **GPT4Rec** <br> <br> *æŠŠLLMç”Ÿæˆçš„æŸ¥è¯¢åºåˆ—åˆ‡åˆ†ä¸ºè¯å…ƒï¼Œç›´æ¥é€šè¿‡BERTè½¬æ¢ä¸ºIDï¼Œæ²¡æœ‰å›ºå®šé•¿åº¦* |
| **Sperate Words** | **SentencePiece åˆ†è¯å™¨** | **P5** <br> <br> *å°†ç”¨æˆ·IDã€ç‰©å“IDç­‰æ‹†åˆ†ä¸ºå¤šä¸ªå­è¯å•å…ƒï¼ˆsub-word unitsï¼‰ï¼Œå¹¶å¼•å…¥ Whole-Word Embeddings æ¥æ ‡è¯†å±äºåŒä¸€åŸå§‹è¯çš„å¤šä¸ªå­è¯* |
| **SVD Tokenizer** | **SVD Tokenizer** | **GPTRec** <br> <br> *å¯¹ç”¨æˆ·-ç‰©å“äº¤äº’çŸ©é˜µè¿›è¡ŒSVDåˆ†è§£ï¼Œå¾—åˆ°ç‰©å“çš„åµŒå…¥å‘é‡ï¼Œå†å°†å…¶é‡åŒ–ä¸ºå¤šä¸ªç¦»æ•£çš„tokenï¼Œä»è€Œæ„å»ºç‰©å“çš„è¯­ä¹‰ï¼›é€šè¿‡å¯¹ä½ç»´ç¨ å¯†åµŒå…¥è¿›è¡Œé‡åŒ–ç¦»æ•£åŒ– æ¥ç”Ÿæˆtokenåºåˆ—ã€‚è¿™ä¸ºæ²¡æœ‰è‡ªç„¶æ–‡æœ¬æè¿°çš„ç‰©å“ï¼ˆå¦‚ä¸€é¦–çº¯éŸ³ä¹ã€ä¸€ä¸ªæ— æ ‡é¢˜å•†å“ï¼‰ç”Ÿæˆè¯­ä¹‰IDæä¾›äº†å¯è¡Œæ–¹æ¡ˆ* |
| **Model-based** | **ID generator** | **IDGenRec** <br> <br> *æå‡ºä¸€ä¸ªåŸºäºLLMçš„IDç”Ÿæˆå™¨ï¼Œä»ç‰©å“çš„å…ƒæ•°æ®ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œç”Ÿæˆç®€æ´ä¸”å…·æœ‰åŒºåˆ†åº¦çš„è¯­ä¹‰IDï¼Œå¹¶ä½¿ç”¨ Diverse ID Generation Algorithm ï¼ˆåŸºäºå¤šæ ·åŒ–æŸæœç´¢ç®—æ³•ï¼‰ç¡®ä¿IDçš„å”¯ä¸€æ€§* |

---

## 3. Generative Backbone
*The architecture modeling the probability of the token sequence.*

| Architecture | Pros & Cons | Representative Papers |
| :--- | :--- | :--- |
| **Encoder-Decoder (T5/BART)** | Bi-directional context encoding; good for mapping History $\to$ Target. | **TIGER**, **P5**, **VQ-Rec** |
| **Decoder-Only (LLM/GPT)** | Strong reasoning & zero-shot ability; standard for LLM-based approaches. | **OneRec**, **GPT4Rec** |
| **Non-Autoregressive (NAR)** | Parallel generation; significantly faster inference but harder to train. | **RPG** (KDD'25) |

| Architecture Family | Sub-Category | Paper's Backbone Focus & Details |
| :--- | :--- | :--- |
| **Encoder-Decoder (T5/BART)** | **Transformer** | **TIGER** <br>  <br> *é‡‡ç”¨æ ‡å‡†çš„ Transformer ç¼–ç å™¨-è§£ç å™¨ æ¶æ„ä½œä¸ºåºåˆ—åˆ°åºåˆ—ç”Ÿæˆæ¨¡å‹* |
| **Encoder-Decoder (T5/BART)** | **T5** | **P5** <br>  <br> *ä½¿ç”¨åŸºäºT5çš„ç¼–ç å™¨-è§£ç å™¨Transformeræ¶æ„ä½œä¸ºæ¨èç³»ç»Ÿçš„ä¸»å¹²æ¨¡å‹* |
| **Encoder-Decoder** | **Two-Stream Generation Architecture**| **EAGER** (arXiv'23) <br> [åŒæµæ¶æ„å›¾] <br> *ä½¿ç”¨ä¸€ä¸ªå…±äº«ç¼–ç å™¨å’Œä¸¤ä¸ªè§£ç å™¨ï¼Œä¸¤ä¸ªè§£ç å™¨åˆ†åˆ«å¯¹åº”ä¸€ç§åºåˆ—ä¿¡æ¯ï¼Œå®ç°äº†åŒæ—¶åŸºäºä¸¤ç§åºåˆ—è¿›è¡Œé¢„æµ‹*  |
| **Only Encoder** | **VQ-Rec**| **VQ-Rec** <br>  <br> *å°†tokenizerç”Ÿæˆçš„ç¦»æ•£codeåœ¨è¾“å…¥transformerå‰åŠ äº†ä¸€æ­¥Code Embedding Lookupï¼Œæ—¶æ¨¡å‹å¯ä»¥é€šè¿‡å¾®è°ƒï¼Œæ”¹å˜å¯¹åº”çš„æŸ¥æ‰¾çŸ©é˜µï¼Œä»¥é€‚åº”ä¸åŒçš„ä¸‹æ¸¸ä»»åŠ¡*  |
| **Decoder-Only (LLM/GPT)** | **LLMs**| **LC-Rec** <br>  <br> *æ¨¡å‹ç°åœ¨ä»¥Sequential Item Predictionä¸ºæ ¸å¿ƒä»»åŠ¡ï¼Œä½¿ç”¨ Explicit Index-Language Alignmentå’Œ Implicit Recommendation-oriented Alignmentå¯¹åŸæœ¬çš„LLMè¿›è¡Œè°ƒæ•´ï¼Œä½¿å…¶èƒ½å¤Ÿé€šè¿‡item IDæ›´å‡†ç¡®çš„é¢„æµ‹ç»“æœ* |
| **Decoder-Only (LLM/GPT)** | **LLMs**| **GPT4Rec** <br>  <br> *é¦–æ¬¡ä½¿ç”¨LLMè¿›è¡Œç”Ÿæˆå¼æ¨è* |
|| **Two-Stream Generation Architecture**| **EAGER** (arXiv'23) <br> [åŒæµæ¶æ„å›¾] <br> *ä½¿ç”¨ä¸€ä¸ªå…±äº«ç¼–ç å™¨å’Œä¸¤ä¸ªè§£ç å™¨ï¼Œä¸¤ä¸ªè§£ç å™¨åˆ†åˆ«å¯¹åº”ä¸€ç§åºåˆ—ä¿¡æ¯ï¼Œå®ç°äº†åŒæ—¶åŸºäºä¸¤ç§åºåˆ—è¿›è¡Œé¢„æµ‹*  |
| **Non-Autoregressive (NAR)** |  | **RPG** <br>  <br> *1.åœ¨åºåˆ—ç¼–ç å™¨ï¼ˆTransformerï¼‰çš„æœ€ç»ˆè¾“å‡ºä¹‹åï¼Œè¿æ¥äº† $m$ ä¸ªç‹¬ç«‹çš„ã€å¹¶è¡Œçš„é¢„æµ‹å¤´ï¼ˆMLPæŠ•å½±å¤´ï¼‰ï¼Œæ¯ä¸ªå¤´ $g_j(Â·)$ è´Ÿè´£é¢„æµ‹è¯­ä¹‰IDä¸­ç¬¬ $j$ ä¸ªä½ç½®ä¸Šçš„tokenã€‚2.å¼•å…¥äº†ä¸€ä¸ªç‰©å“çº§åˆ«çš„èšåˆè¡¨ç¤ºå±‚ã€‚ä»–ä»¬å…ˆå°†ä¸€ä¸ªç‰©å“çš„æ‰€æœ‰tokenåµŒå…¥è¿›è¡Œèšåˆï¼Œå¾—åˆ°ä¸€ä¸ªå•ä¸€çš„ç‰©å“å‘é‡ $v_i$ï¼Œå†å°†è¿™ä¸ªç‰©å“å‘é‡ä½œä¸ºåºåˆ—æ¨¡å‹çš„è¾“å…¥*  |
| **Non-Autoregressive (NAR)** |  | **LLaDA-Rec** <br>  <br> *é‡‡ç”¨åŸºäºåŒå‘Transformerçš„ç¦»æ•£æ‰©æ•£æ¨¡å‹ä½œä¸ºç”Ÿæˆæ¨¡å‹çš„æ ¸å¿ƒ*  |

---

## 4. Training Paradigm
*How the system is optimized and aligned.*

| Paradigm | Description | Representative Papers |
| :--- | :--- | :--- |
| **Two-Stage (Quantize $\to$ Train)** | Step 1: Train Codebook (VQ-VAE). Step 2: Train Generator (Seq2Seq). | **TIGER**, **VQ-Rec** |
| **Joint / End-to-End** | Optimizing quantization loss and generation loss simultaneously. | **LC-Rec**, **GeneRec** |
| **Pre-train & Fine-tune** | Standard LLM paradigm: Language Modeling pre-training $\to$ Rec fine-tuning. | **GPT4Rec**, **P5** |
| **Alignment (RLHF/DPO)** | Aligning generation with ranking metrics or user feedback (Reinforcement Learning). | **OneRec** (Preference Alignment) |

| Paradigm Family | Sub-Category | Paper's Paradigm Focus & Details |
| :--- | :--- | :--- |
| **Two-Stage (Quantize $\to$ Train)** | | **TIGER** <br> <br> *Step 1: Train Codebook (VQ-VAE). Step 2: Train Generator (Seq2Seq).* |
| **Two-Stage (Quantize $\to$ Train)** | | **LETTER** <br> <br> *æå‡ºåœ¨è®­ç»ƒç æœ¬çš„è¿‡ç¨‹ä¸­å°†è¯­ä¹‰é‡å»ºã€ååŒå¯¹é½å’Œå¤šæ ·æ€§æ­£åˆ™åŒ–ä¸‰ä¸ªç›®æ ‡è”åˆèµ·æ¥è®­ç»ƒåˆ†è¯å™¨ï¼Œå¹¶æå‡ºæ’åºå¼•å¯¼çš„ç”ŸæˆæŸå¤±ï¼Œé€šè¿‡è°ƒèŠ‚æ¸©åº¦å‚æ•°æ¥åŠ å¤§å¯¹éš¾è´Ÿæ ·æœ¬çš„æƒ©ç½šï¼Œé¦–æ¬¡åœ¨ç†è®ºå’Œå·¥ä½œä¸Šå°†ç”Ÿæˆå¼æŸå¤±ä¸æ¨èç³»ç»Ÿçš„æ’åºç›®æ ‡ç›´æ¥è”ç³»èµ·æ¥* |
| **Two-Stage (Quantize $\to$ Train)** | **Alternate Training** | **IDGenRec** <br> <br> *é¦–æ¬¡æå‡ºäº†äº¤æ›¿è®­ç»ƒçš„èŒƒå¼ï¼Œå¹¶é€šè¿‡åµŒå…¥æ’å€¼å®ç°æ¢¯åº¦åå‘ä¼ æ’­ï¼Œåˆ†åˆ«è®­ç»ƒIDç”Ÿæˆå™¨å’Œæ¨èå™¨ï¼Œé¿å…åŒæ—¶è®­ç»ƒçš„ä¸ç¨³å®šæ€§* |
| **Two-Stage (Quantize $\to$ Train)** | **Multi-Task Enhancement** | **EAGER** (arXiv'23) <br> [åŒæµæ¶æ„å›¾] <br> *æ·»åŠ äº†ä¸€ä¸ªGlobal Ctracive Taskå’Œä¸€ä¸ªSemantic-guided transformer Taskï¼Œå‰ä¸€ä¸ªåŠ å¼ºäº†æ¨¡å‹å¯¹tokenså…¨å±€çš„åˆ¤åˆ«èƒ½åŠ›ï¼Œåè€…ä½¿ç”±åŒæµæ¨¡å‹çš„ä¸¤ä¸ªæµä¹‹é—´ä¹‹é—´äº§ç”Ÿä¿¡æ¯äº¤æ¢ï¼Œè¿™ä¸¤è€…éƒ½æ˜¯è¾…åŠ©è®­ç»ƒç›®æ ‡* |
| **Two-Stage (Quantize $\to$ Train)** | **Multi-Task Enhancement** | **ColaRec**  <br> <br> *å¼•å…¥ Item-Item Indexingå’Œcontrastive lossï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿç†è§£ä»itemåˆ°GIDçš„æ˜ å°„åŠæ‹‰è¿‘ç›¸ä¼¼GIDåœ¨è¯­ä¹‰åµŒå…¥ä¸Šçš„è·ç¦»ï¼Œå®ç°è¯­ä¹‰å’ŒCFä¿¡å·çš„å¯¹å…¶æœºåˆ¶ã€‚* |
| **Two-Stage (Quantize $\to$ Train)** | **Mix of Generative and Dense Retrieval** | **LIGER**  <br> <br> *ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æŸå¤±ä¸the next-token prediction losså½¢æˆåŒç›®æ ‡æŸå¤±ï¼Œå®ç°ç¨ å¯†æ£€ç´¢ä¸ç”Ÿæˆå¼æ£€ç´¢ç»“åˆçš„æ•ˆæœ* |
| **Two-Stage (Quantize $\to$ Train)** | **MTP** | **RPG** <br> <br> *å¼•å…¥å¹¶é€‚åº”äº†â€œå¤štokené¢„æµ‹â€ç›®æ ‡ã€‚è¯¥ç›®æ ‡è®©æ¨¡å‹åŒæ—¶é¢„æµ‹è¯­ä¹‰IDçš„æ‰€æœ‰tokenï¼Œä»è€Œæ‰“ç ´äº†tokené—´çš„é¡ºåºä¾èµ–ï¼Œå®ç°å¹¶è¡Œè§£ç ã€‚* |
| **Two-Stage (Quantize $\to$ Train)** | **åŒå±‚æ¬¡æ©ç è®­ç»ƒ** | **LLaDA-Rec** <br> <br> *ä½¿ç”¨User-History Level Maskingï¼Œå®ç°ç‰©å“é—´çš„åºåˆ—ä¾èµ–å…³ç³»çš„å­¦ä¹ ï¼Œä½¿ç”¨Next-Item Level Maskingï¼Œå®ç°å‹ç‰©å“å†…çš„è¯­ä¹‰ç»“æ„çš„å­¦ä¹ * |
| **Joint / End-to-End** | **alignment tuning** | **LC-Rec** <br>  <br> *æ¨¡å‹ç°åœ¨ä»¥Sequential Item Predictionä¸ºæ ¸å¿ƒä»»åŠ¡ï¼Œä½¿ç”¨ Explicit Index-Language Alignmentå’Œ Implicit Recommendation-oriented Alignmentå¯¹åŸæœ¬çš„LLMè¿›è¡Œè°ƒæ•´ï¼Œå®ç°llmä¸item IDçš„å¯¹é½* |
| **Joint / End-to-End** | **Quantizeä¸TrainååŒ** | **ETEGRec** <br>  <br> *å°†item tokenizationå’Œgenerative recommendationåœ¨ä¸€ä¸ªæ¡†æ¶ä¸­è”åˆä¼˜åŒ–ï¼Œå¹¶æå‡ºSequence-Item Alignmentå’ŒPreference-Semantic Alignmentå¯¹é½ç­–ç•¥ï¼Œå®ç°åºåˆ—åˆ°ç‰©å“åˆ†å¸ƒä»¥åŠåå¥½åˆ°è¯­ä¹‰çš„å¯¹é½ï¼›åŒæ—¶æå‡ºäº¤æ›¿ä¼˜åŒ–ç­–ç•¥ï¼Œè§£å†³ç«¯åˆ°ç«¯è®­ç»ƒçš„ä¸ç¨³å®šæ€§* |
| **Joint / End-to-End** | **ä»¥end-to-endä¸ºéª¨æ¶ï¼ŒåµŒå…¥alignment** | **GREAM** <br>  <br> *åˆ›å»ºå¤šå±‚æ¬¡å¯¹é½ä»»åŠ¡ï¼ŒåŒ…æ‹¬é¡ºåºæ¨èä»»åŠ¡ï¼Œè¯­ä¹‰é‡å»ºä»»åŠ¡åŠç”¨æˆ·åå¥½ä»»åŠ¡ï¼Œå®ç°åœ¨LLMçš„è¡¨ç¤ºç©ºé—´ä¸­ï¼Œå»ºç«‹ä¸€ä¸ªåŒæ—¶æ‰¿è½½äº†è¯­è¨€è¯­ä¹‰å’Œåä½œè¯­ä¹‰çš„æ··åˆè¡¨ç¤ºï¼›åœ¨ä¼ ç»Ÿæ¨ç†é“¾ä¸ŠåŠ å…¥å»å™ªåºåˆ—é‡å†™ï¼Œå®ç°æ¨¡å‹ä¸»åŠ¨è¯†åˆ«å¹¶è¿‡æ»¤æ‰ç”¨æˆ·å†å²ä¸­çš„å™ªå£°äº¤äº’ï¼›ä½¿ç”¨åˆæˆCoTæ•°æ®ï¼Œåå‘æ¨ç†ç”Ÿæˆé«˜è´¨é‡æ•°æ®é›†ï¼Œå°†SFTä¸è¯¾ç¨‹å­¦ä¹ è°ƒåº¦ç›¸èåˆï¼›æå‡ºSRPO ç®—æ³•ï¼ˆåŒ…æ‹¬æ®‹å·®æ•æ„Ÿçš„å¯éªŒè¯å¥–åŠ±ï¼Œå¥–åŠ±æ ¡å‡†çš„ä¼˜åŠ¿ä¼°è®¡å’Œæ–¹å·®å¼•å¯¼çš„åŠ¨æ€é‡‡æ ·ï¼‰ï¼Œè§£å†³åº”ç”¨RLHFä¼šå› å¥–åŠ±ç¨€ç–å¯¼è‡´è®­ç»ƒä¸ç¨³å®šã€éš¾ä»¥æ”¶æ•›* |
| **Pre-train & Fine-tune** | **multi-task** | **P5**  <br>  <br> *1.é¢„è®­ç»ƒï¼šåœ¨ä¸€ä¸ªç”±å¤šç§æ¨èä»»åŠ¡æ„æˆçš„ã€é€šè¿‡ä¸ªæ€§åŒ–æç¤ºæ¨¡æ¿æ ¼å¼åŒ–åçš„ç»Ÿä¸€æ•°æ®é›†ä¸Šè¿›è¡Œé¢„è®­ç»ƒã€‚2.æç¤ºä¸é¢„æµ‹ï¼šé¢„è®­ç»ƒç»“æŸåï¼Œä¸éœ€è¦å¾®è°ƒã€‚é€šè¿‡æ”¹å˜è¾“å…¥æ¨¡å‹çš„æç¤ºï¼Œç›´æ¥è®©æ¨¡å‹æ‰§è¡Œä¸åŒçš„ä»»åŠ¡ã€‚* |
| **Pre-train & Fine-tune** | | **VQ-Rec**  <br>  <br> *åœ¨ä¼ ç»Ÿçš„é¢„è®­ç»ƒ-å¾®è°ƒèŒƒå¼çš„åŸºç¡€ä¸Šï¼Œåœ¨é¢„è®­ç»ƒæ—¶ï¼Œä½¿ç”¨å¯¹æ¯”å­¦ä¹ ï¼Œä¿è¯æ¨¡å‹åœ¨å¤šé¢†åŸŸçš„é€‚åº”æ€§ï¼Œåœ¨å¾®è°ƒé˜¶æ®µæå‡ºpermutation-based alignmentå®Œæˆå¯¹code embedding tableå¯¹äºä¸åŒä¸‹æ¸¸ä»»åŠ¡çš„è°ƒæ•´* |
| **Pre-train & Fine-tune** | **Cross-modal** | **MQL4GRec**  <br>  <br> *å¼•å…¥Asymmetric Item Generation å’Œ Quantitative Language Alignment å®ç°æ¨¡æ€é—´çš„çŸ¥è¯†è¿ç§»ä¸å¯¹é½* |
| **Pre-train & Fine-tune** | **Alpaca Tuning + Rec-Tuning** | **TALLRec**  <br>  <br> *ä½¿ç”¨æŒ‡ä»¤å¾®è°ƒï¼Œè½»é‡åŒ–å¾®è°ƒæŠ€æœ¯ï¼ˆLoRAï¼‰ï¼Œå°æ ·æœ¬è®­ç»ƒï¼ˆFew-shot Trainingï¼‰å»è®©LLMéª¨æ¶é€‚åº”æ¨èä»»åŠ¡* |
| **Alignment (RLHF/DPO)** | **Alignment+fine-tune** | **OneRec**  <br>  <br> *ä½¿ç”¨èç³»ç»Ÿçš„æ•°æ®ï¼ˆç‰©å“çš„è¯­ä¹‰IDåºåˆ—ï¼‰å¯¹å…¶è¿›è¡Œç›‘ç£å¾®è°ƒï¼Œåœ¨ä½¿ç”¨GRPOæ¥å¯¹é½å’Œä¼˜åŒ–æ¨¡å‹çš„ç”Ÿæˆåå¥½ï¼ˆå…·ä½“æ–¹æ³•ä¸ºå…¨æµç¨‹SID-æ–‡æœ¬å¯¹é½å’Œæ’åºæ„ŸçŸ¥çš„å¥–åŠ±å‡½æ•°ï¼‰* |

---

## 5. Inference & Decoding
*Strategies to generate valid items and rank them efficiently.*

| Strategy | Description | Representative Papers |
| :--- | :--- | :--- |
| **Constrained Beam Search** | Using a Prefix Tree (Trie) to force the generator to output valid Item IDs. | **TIGER**, **GenRet**, **LETTER** |
| **Standard Beam Search** | Generating top-K sequences based on probability (may hallucinate invalid IDs). | **GPT4Rec** |
| **Parallel / Graph Decoding** | Non-autoregressive decoding guided by graph constraints. | **RPG** |
| **Re-ranking / Scoring** | Using the generator to score candidates retrieved by another model. | **LLaRA**, **TALLRec** |

| Family | Sub-Category | Details |
| :--- | :--- | :--- |
| **Constrained Beam Search** | **beam serch + Temperature-based sampling** | **TIGER** <br> <br> *ä½¿ç”¨ Beam Search è¿›è¡Œè‡ªå›å½’è§£ç ä»¥ç”Ÿæˆè¯­ä¹‰IDï¼Œå¹¶å¼•å…¥äº†æ¸©åº¦é‡‡æ ·æ¥æ§åˆ¶æ¨èå¤šæ ·æ€§* |
| **Constrained Beam Search** | **Conffdence-based Ranking** | **EAGER** (arXiv'23) <br> [åŒæµæ¶æ„å›¾] <br> *åœ¨åŒæµæ¨¡å‹çš„æ¯ä¸ªæµä¸­ä½¿ç”¨beam searchï¼Œåˆ†åˆ«é€‰å‡ºå„è‡ªçš„top-kï¼Œç„¶åå¯¹è¿™2kçš„é¢„æµ‹ç»“æœä¸­ï¼Œè®¡ç®—ä»–ä»¬çš„log probabilitiesï¼Œå€¼è¶Šå°ä»£è¡¨å¯èƒ½æ€§è¶Šå¤§ï¼Œå¯¹è¿™2kä¸ªç»“æœçš„åˆ†æ•°è¿›è¡Œæ’åºï¼Œå–top-kä¸ºç»“æœ* |
| **Constrained Beam Search** |  | **GPT4RecR** <br>  <br> *æå‡ºå°†åŸæœ¬çš„LLMç”Ÿæˆæ–¹å¼åªä¿ç•™beam search çš„å…¶ä¸­ä¸€ä¸ªï¼Œæ”¹ä¸ºä¿ç•™å¤šä¸ªå¯èƒ½é€‰é¡¹* |
| | **beam serch** | **LC-Rec**  <br>  <br> *ä½¿ç”¨beam searchæ›¿æ¢LLMåŸæœ¬çš„å€™é€‰é›†inferenceæ–¹æ³•ï¼Œå¹¶ä¸”åˆ©ç”¨KV bufferåŠ é€Ÿè¿™ä¸€è¿‡ç¨‹ï¼Œå¹¶ä¸”åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­è¿‡æ»¤æ‰éæ³•ç´¢å¼•ç»„åˆã€‚* |
| | **é€‚ç”¨äºç¦»æ•£æ‰©æ•£** | **LC-Rec**  <br>  <br> *åŒ…å«ä¸‰æ­¥ï¼š1.è‡ªé€‚åº”ç”Ÿæˆé¡ºåºï¼šåœ¨æ¯ä¸€æ­¥ï¼Œé€‰æ‹©æ¨¡å‹ç½®ä¿¡åº¦æœ€é«˜ï¼ˆè€Œéå›ºå®šä½ç½®ï¼‰çš„tokenè¿›è¡Œç”Ÿæˆã€‚2.æŸæœç´¢é›†æˆï¼šåœ¨é€‰å®šçš„ä½ç½®ä¸Šè¿›è¡ŒæŸæ‰©å±•å’Œå‰ªæï¼Œä»¥ç”Ÿæˆtop-kæ¨èç»“æœã€‚3.è¿­ä»£ç²¾ç‚¼ï¼šç”ŸæˆæŸäº›ä½ç½®åï¼Œå¯¹å‰©ä½™ä½ç½®ä¿¡åº¦çš„ä½ç½®è¿›è¡Œé‡æ–°æ©ç ï¼Œåœ¨åç»­æ­¥éª¤ä¸­åˆ©ç”¨æ–°çš„ä¸Šä¸‹æ–‡ä¿¡æ¯é‡æ–°é¢„æµ‹ã€‚* |
| **Standard Beam Search** | **Multi - mode** | **GREAM** <br>  <br> *æœ‰ä¸¤ç§æ¨èæ¨¡å¼ï¼Œä¸€ç§åŸºäºCF signals,å¦ä¸€ç§å…ˆåŸºäºé€»è¾‘ç”Ÿæˆå†åŸºäºCFä½†æ˜¯ä¸¤æ­¥ç­›é€‰éƒ½åŸºäºbeam search* |
| **Parallel / Graph Decoding** | | **RPG**<br>  <br> *ä¸ºæ‰€æœ‰æœ‰æ•ˆçš„è¯­ä¹‰IDæ„å»ºä¸€ä¸ªå›¾ç»“æ„ï¼Œå¹¶é€šè¿‡è¿­ä»£çš„å›¾ä¼ æ’­æ¥å¼•å¯¼è§£ç è¿‡ç¨‹ï¼Œå®ç°äº†åœ¨å·¨å¤§çš„å€™é€‰ç©ºé—´ä¸­æ‰¾åˆ°é«˜åˆ†çš„ã€æœ‰æ•ˆçš„è¯­ä¹‰IDï¼Œè€Œä¸éœ€è¦æšä¸¾æ‰€æœ‰ç‰©å“ï¼Œæœ¬è´¨æ˜¯å…ˆé€šè¿‡ä¹‹å‰æ„å»ºçš„è§£ç å›¾æ‰¾åˆ°é«˜åˆ†å€™é€‰çš„ç›¸ä¼¼è¯­ä¹‰IDï¼Œå†è®¡ç®—scoreå¾—åˆ°æ–°çš„é«˜åˆ†å€™é€‰ï¼Œç”±æ­¤è¿­ä»£qæ¬¡ï¼Œæœ€ç»ˆæ‰¾åˆ°æœ€ä¼˜* |
| **Re-ranking / Scoring** | **beam serch+scoring+ranking** |  **LIGER** <br> <br> *inferenceåˆ†ä¸ºä¸¤æ­¥ï¼Œç¬¬ä¸€æ­¥ä½¿ç”¨beam searchå¾—åˆ°ä¸€ä¸ªåˆå§‹å€™é€‰åˆ—è¡¨ï¼Œåœ¨ä½¿ç”¨ä¸€ä¸ªå¤–éƒ¨æ‰“åˆ†å™¨ï¼ˆä½¿ç”¨ç¨ å¯†æ£€ç´¢çš„ç›¸ä¼¼åº¦è®¡ç®—ï¼‰ æ¥å¯¹ç”Ÿæˆæ¨¡å‹å¾—åˆ°çš„å€™é€‰åˆ—è¡¨è¿›è¡Œé‡æ–°æ’å*  |
| **Re-ranking / Scoring** | **scoring+ranking** |  **MQL4GRec** <br> <br> *æ¨¡å‹åŒæ—¶ä¼šè¾“å‡ºåŸºäºå›¾åƒä¸æ–‡æœ¬çš„åå¥½æ¨èåˆ—è¡¨ï¼Œå°†ç‰©å“åœ¨ä¸åŒåˆ—è¡¨çš„åˆ†æ•°ç›¸åŠ ï¼ˆå¦‚æœè¯¥ç‰©å“åªåœ¨ä¸€ä¸ªåˆ—è¡¨åˆ™åªç®—è¿™ä¸€ä¸ªåˆ—è¡¨ä¸­çš„å¾—åˆ†ï¼‰ä½œä¸ºæœ€ç»ˆå¾—åˆ†ï¼Œå†å¯¹ä¸¤ä¸ªåˆ—è¡¨çš„å†…å®¹è¿›è¡Œé‡æ’ï¼Œå–top-k*  |
| **Constrained Decoding** | **Constrained Decoding** |  **IDGenRec** <br> <br> *åœ¨æ¨ç†é˜¶æ®µä½¿ç”¨çº¦æŸè§£ç ï¼ˆConstrained Decodingï¼‰ï¼ŒåŸºäºå‰ç¼€æ ‘ï¼ˆprefix treeï¼‰ç¡®ä¿ç”Ÿæˆçš„IDå¿…é¡»æ˜¯æ•°æ®é›†ä¸­å­˜åœ¨çš„ç‰©å“IDã€‚*  |
| **Multiple Way** | **Multiple Way** |  **P5** <br> <br> *æ ¹æ®ä»»åŠ¡ç±»å‹ï¼Œè‡ªé€‚åº”åœ°é€‰æ‹©è§£ç ç­–ç•¥ï¼šå¯¹æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä½¿ç”¨è´ªå¿ƒè§£ç ï¼Œå¯¹ç‰©å“æ¨èä»»åŠ¡ä½¿ç”¨æŸæœç´¢ã€‚*  |

---
